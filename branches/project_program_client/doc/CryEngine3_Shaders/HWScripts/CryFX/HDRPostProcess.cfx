#include "Common.cfi"
#include "ShadeLib.cfi"
#include "ModificatorVT.cfi"
#include "PostEffectsLib.cfi"

// Possible optimizations: 
//  - bloom 1st step gaussian blur: using 8 taps gaussian blur a bit too much for consoles

// Improves:
//  - all FP render targets for very hi specs

#define USE_LUM_CONTRAST
#define USE_LUM_AVG
#define USE_EXP_MAPPING

// tone mapping tests
//#define USE_DRAGO_LOG_MAPPING
//#define USE_SCHLICK_UNIFORM_MAPPING
//#define USE_REINHARD_MAPPING_TEST
//#define USE_REINHARD_MAPPING

// Shader global descriptions
float Script : STANDARDSGLOBAL
<
  string Script =
           "NoPreview;"
           "LocalConstants;"
           "ShaderDrawType = Custom;"
           "ShaderType = HDR;"
>;

/// Un-Tweakables //////////////////////
float4 ScreenSize  : PB_ScreenSize;

float4 SampleOffsets[16] < register = c0; >
float4 SampleWeights[16] < register = c16; >
float4x4 HDRColorMatrix;

half4 HDRParams0;				// (r_hdreyeadaptationfactor,r_hdrbrightoffset,r_hdrbrightthreshold,r_HDRBrightLevel)
half4 HDRParams1;				// (r_hdreyeadaptationbase,r_HDRLevel,r_HDROffset,*)
half4 HDRParams2;				// (*, *, r_HDRContrast, r_HDRContrastLuminanceBlend)
half4 HDRParams3;				// (*, *, vignetting threshold, vignetting amount)

#define PROFILE_PS ps_2_0
#define PROFILE_VS vs_2_0

float4 ElapsedTime;
float4 FrameRand;
float Time = {PB_time};

half g_fBloomScale = 2.5f;

sampler2D zMap : register(s0);
sampler2D sceneMap0 : register(s0);
sampler2D sceneMap1 : register(s1);
sampler2D sceneMap2 : register(s2);
sampler2D sceneMap3 : register(s3);

// Specific for final tone map pass
sampler2D lumMap    : register(s1);
sampler2D bloomMap0 : register(s2);
sampler2D bloomMap1 : register(s3);
sampler2D bloomMap2 : register(s4);
sampler2D colorChartMap : register(s5);
sampler2D noiseMap : register(s6);
sampler2D vignettingMap : register(s7);

sampler2D baseMap : register(s0);
sampler2D bloomMap : register(s1);

sampler2D lumMap0    : register(s0);
sampler2D lumMap1    : register(s1);


struct app2vert
{
  IN_P
  IN_TBASE
  IN_C0
};

struct app2vertFog
{
  IN_P
  float3 CamVec    : TEXCOORD0;
};

struct vert2frag
{
  float4 HPosition  : POSITION;
  float4 baseTC     : TEXCOORD0;
};

struct vert2fragFog
{
  float4 HPosition  : POSITION; 
  float2 baseTC       : TEXCOORD0;
  float3 CamVec       : TEXCOORD1;
};

/////////////////////////////////////////////////////////////////////////////////////
// Output/Get luminance helpers (PS3 needs platform specific workaround due to missing R16G16F)

half4 GetLuminanceMap( sampler2D lum, float2 tc )
{
  return tex2D(lum, tc);
}

#if PS3

float4 OutputLuminanceMap( half4 lum )
{
  return pack_2half( lum.xy ).xxxx;
}

#else

half4 OutputLuminanceMap( half4 lum )
{
  return lum;
}

#endif

/////////////////////////////////////////////////////////////////////////////////////

// RangeReducedAdaptedLum
half EyeAdaption( half fSceneLuminance )
{
  #if %_RT_SAMPLE4
    half ret = HDRParams1.w;
  #else
	  half ret = lerp(HDRParams1.x,fSceneLuminance,HDRParams0.x);	// good values: r_hdreyeadaptationbase=0.25, r_hdreyeadaptationfactor=0.5
  #endif
	// reinhard white-point
	//half ret = lerp(HDRParams1.x,fSceneLuminance,HDRParams0.x); // good values: r_hdreyeadaptationbase=0.2, r_hdreyeadaptationfactor=0.35

	return ret;
}

// Note: DirectX will skip the vshader for vformats containing a transformed
// position (VERTEX_FORMAT_TRP3F_*). The PreTransformedVS shader is executed
// only for platforms that do not support pre-transformed verts (e.g. OpenGL).
vert2frag PreTransformedVS(app2vert IN)
{
  vert2frag OUT = (vert2frag)0; 

	// Position in pixel coordinates (i.e. 0 thru ScreenSize - 1).
  float4 vPos = IN.Position;
  OUT.HPosition = float4(
			2.0f * (vPos.xy + 0.5f) / ScreenSize.xy - 1.0f, vPos.zw);
  OUT.baseTC.xy = IN.baseTC.xy;

  return OUT;
}

vert2frag TransformedVS(app2vert IN)
{
  vert2frag OUT = (vert2frag)0; 

  // Position in screen space.
  float4 vPos = IN.Position;
  OUT.HPosition = vPos;
  
  float2 baseTC = vPos.xy * float2(0.5, -0.5) + 0.5;
#if !D3D10 && !PS3
  OUT.HPosition.xy += float2(-0.5, 0.5) * g_VS_ScreenSize.zw;
#endif
  
  OUT.baseTC.xy = baseTC;    
  OUT.baseTC.wz = (baseTC / 64.0) * g_VS_ScreenSize.xy + FrameRand.xy;
  
  return OUT;
}

vert2fragFog PreTransformedFogVS(app2vertFog IN)
{
	vert2fragFog OUT = (vert2fragFog)0;

  OUT.baseTC.xy = IN.Position.xy * float2(0.5, -0.5) + 0.5;
	OUT.CamVec.xyz = IN.CamVec.xyz;

	OUT.HPosition = IN.Position;
#if !D3D10 && !PS3
  OUT.HPosition.xy += 2 * float2(-g_VS_ScreenSize.z, g_VS_ScreenSize.w);
#endif  

	return OUT;
}

vert2frag TransformVS(app2vert IN)
{
  vert2frag OUT = (vert2frag)0; 

  // Position in screen space.
  float4 vPos = IN.Position;
  OUT.HPosition = mul(vpMatrix, vPos);
  
  OUT.baseTC.xy = IN.baseTC.xy;

  return OUT;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////

pixout HDRBrightPassFilterPS(vert2frag IN)
{
  pixout OUT;
  
  half4 vSample;
  vSample = tex2D(baseMap, IN.baseTC.xy) * HDRParams2.y; // fetch half res scene target and apply range scale

#if !XENON && !PS3

	// this way we check for NAN (illegal floats) as HLSL optimized the isnan() away
	// visible mostly on NVIDIA, if possible this should be removed and no shader should produce NAN
	  vSample.rgb = (vSample.rgb> 10000.0f)? half3(1, 1, 1): vSample.rgb;

#endif

// with abs() it might be more stable
	//if(abs(dot(vSample, 0.333)) > 10000.0f) vSample =1.0f;

  half fAdaptedLum = GetLuminanceMap(lumMap1, float2(0.5f, 0.5f));

  half Level = HDRParams0.w;
  half BrightOffset = HDRParams0.y;
  half BrightThreshold = HDRParams0.z;
  
	half fAdaptedLumDest = EyeAdaption(fAdaptedLum);

  // Determine what the pixel's value will be after tone-mapping occurs
	vSample.rgb *= Level/(fAdaptedLumDest + 1e-6);
  vSample.rgb -= BrightThreshold;
  vSample.rgb = max(vSample.rgb, (half3)0.0);

  // Map the resulting value into the 0 to 1 range. Higher values for
  // BRIGHT_PASS_OFFSET will isolate lights from illuminated scene 
  // objects.
   vSample.rgb /= (BrightOffset + vSample.rgb);

  // We add lightshafts only on brightpass since it looks better/smoother than adding directly to HDRScene

  // will need encode/decode if quality < med
  half4 cLightShafts = 0;
  #if %_RT_SAMPLE2
    cLightShafts = ( tex2D(sceneMap2, IN.baseTC.xy) );  
    // Use rgbs if fp16 filtering not supported
    #if !%BILINEAR_FP16  
      cLightShafts.xyz = DecodeRGBS( cLightShafts );  
    #endif     
  #endif
       
  OUT.Color = vSample + cLightShafts;
	
	// 1st optimal case: store in FP format
	// 2nd optimal case: store in gamma space

  return OUT;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////
// Note: on PS3 we use a workaround format (X32F) for missing RG16F - need to output full precision

half4 SampleLumOffsets0;
half4 SampleLumOffsets1;

pixout_fp HDRSampleLumInitialPS(vert2frag IN)
{
  pixout_fp OUT = (pixout_fp) 0;
  
  half fRecipSampleCount = 0.25h;
  half2 vLumInfo = half2(0.0h, 64.0h);//, -64.0h); 

  half3 cTex = tex2D(baseMap, IN.baseTC.xy + SampleLumOffsets0.xy).rgb * HDRParams2.y;
	half fLum = GetLuminance(cTex.rgb);
#if USE_LUM_AVG
	vLumInfo.x += fLum;
#else
	vLumInfo.x += log(fLum + 1e-6);
#endif
  vLumInfo.y = min(vLumInfo.y, fLum);

  cTex = tex2D(baseMap, IN.baseTC.xy + SampleLumOffsets0.zw).rgb * HDRParams2.y;
	fLum = GetLuminance(cTex.rgb);
#if USE_LUM_AVG
	vLumInfo.x += fLum;
#else
	vLumInfo.x += log(fLum + 1e-6);
#endif
  vLumInfo.y = min(vLumInfo.y, fLum);

  cTex = tex2D(baseMap, IN.baseTC.xy + SampleLumOffsets1.xy).rgb * HDRParams2.y;
	fLum = GetLuminance(cTex.rgb);
#if USE_LUM_AVG
	vLumInfo.x += fLum;
#else
	vLumInfo.x += log(fLum + 1e-6);
#endif
  vLumInfo.y = min(vLumInfo.y, fLum);

  cTex = tex2D(baseMap, IN.baseTC.xy + SampleLumOffsets1.zw).rgb * HDRParams2.y;
	fLum = GetLuminance(cTex.rgb);
#if USE_LUM_AVG
	vLumInfo.x += fLum;
#else
	vLumInfo.x += log(fLum + 1e-6);
#endif
  vLumInfo.y = min(vLumInfo.y, fLum);

  // clamp to acceptable range
  OUT.Color.xy = min(vLumInfo.xy * half2(fRecipSampleCount, 1), 64);
  //OUT.Color.xy = vLumInfo.xx * fRecipSampleCount * half2(1, 4);

  OUT.Color = OutputLuminanceMap( OUT.Color );;

  return OUT;
}


pixout_fp HDRSampleLumInitialPS_old(vert2frag IN)
{
  pixout_fp OUT = (pixout_fp) 0;
  
  int iSampleCount=8; //9

  half fRecipSampleCount = 1.0h / (half) iSampleCount;

  half2 vLumInfo = half2(0.0h, 64.0h);//, -64.0h); 

   // Compute the sum of log(luminance) throughout the sample points
  for(int i=0; i<iSampleCount; i++)
  {
    half3 cTex;
		cTex = tex2D(baseMap, IN.baseTC.xy+SampleOffsets[i].xy).rgb * HDRParams2.y;

		half fLum = GetLuminance(cTex.rgb);
#if USE_LUM_AVG
		vLumInfo.x += fLum;
#else
		vLumInfo.x += log(fLum + 1e-6);
#endif
    vLumInfo.y = min(vLumInfo.y, fLum);
    //vLumInfo.z = max(vLumInfo.z, fLum);
	} 

	//vLumInfo.y -= vLumInfo.z;
  // clamp to acceptable range
  OUT.Color.xy = min(vLumInfo.xy * half2(fRecipSampleCount, 1), 64);
  //OUT.Color.xy = vLumInfo.xx * fRecipSampleCount * half2(1, 4);

  OUT.Color = OutputLuminanceMap( OUT.Color );;

  return OUT;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////

pixout_fp HDRSampleLumIterativePS(vert2frag IN)
{
  pixout_fp OUT = (pixout_fp) 0;

  int nIter = 16;
#if %BILINEAR_FP16
  nIter = 4;
#endif    
  half nRecipIter = 1.0h / (half) nIter;

  half4 vResampleSum = 0.0f; 
  for(int i=0; i<nIter; i++)
  {
    // Compute the sum of luminance throughout the sample points
    half2 vTex = GetLuminanceMap(baseMap, IN.baseTC.xy+SampleOffsets[i].xy);
    vResampleSum.xy += vTex.xy;

   // correct maximum 
   //vResampleSum.x += vTex.x;
   //vResampleSum.y = max(vResampleSum.y, vTex.y);
  }
  
  // Divide the sum to complete the average
 //vResampleSum.x *= nRecipIter;
 vResampleSum.xy *= nRecipIter;

  OUT.Color = vResampleSum;

#if %_RT_SAMPLE0 
  //rOUT.Color.xy = vResampleSum * float2(1, 16.0h);
	#if !USE_LUM_AVG
		OUT.Color.x = exp( vResampleSum.x );
	#endif
#endif

  OUT.Color = OutputLuminanceMap( OUT.Color );
  
  return OUT;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////
// Final eye/luminance adaptation

pixout_fp HDRCalculateAdaptedLumPS(vert2frag IN)
{
  pixout_fp OUT = (pixout_fp) 0;
  
  half4 vAdaptedLum = GetLuminanceMap(lumMap0, 0.5h);
  half4 vCurrentLum = GetLuminanceMap(lumMap1, 0.5h);

  // Check for bad fp conditions
	if( vCurrentLum.x * ElapsedTime.w != 0.0h )
		vCurrentLum=1.0f;

	if( vAdaptedLum.x * ElapsedTime.w != 0.0h )
		vAdaptedLum=1.0f;
 
  half4 vNewAdaptation = max(0, vAdaptedLum + (vCurrentLum - vAdaptedLum) *  ElapsedTime.yzzz);
  OUT.Color = OutputLuminanceMap( vNewAdaptation );

  return OUT;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Tone mappers

half4 ReinhardMappingTest( in vert2frag IN, in half4 cScene, in half4 cBloom, in half fAdaptedLum, in half fVignetting )
{
  // Reinhard with White Point

	half3 LUMINANCE_VECTOR  = half3 (0.2125h, 0.7154h, 0.0721h);

	// todo: combine fTargetAvgLum into fAdaptedLumDest
	const half fWhitePoint = 1.2;
	const half fTargetAvgLum = 0.22f;

	const half fInvWhitePoint2 = 1.0f/(fWhitePoint*fWhitePoint);  

	half fAdaptedLumDest = EyeAdaption(fAdaptedLum);		// RangeReducedAdaptedLum

	half fLum = dot(half4(cScene.rgb,1),half4(LUMINANCE_VECTOR,0.000001f));		// add small value to avoid division by 0

	half3 cBlackColor = float3(0.0f,0.0f,0.0f);;
	half fBlackLevel=0;

  cScene.rgb = lerp((0.5+0.5*tex2D(noiseMap,IN.baseTC.wz).xyz) * (fLum+fBlackLevel) * half3(0.8f,0.8f,1.4f)*2.0f, cScene.rgb, saturate(5.0f*fLum));

	half Ls = fTargetAvgLum * fLum / fAdaptedLumDest;
	half Ld = Ls * (1+Ls*fInvWhitePoint2) / (1+Ls);
	
	cScene.rgb *= Ld/fLum;

  // desaturate
  half fSaturation=0.8f;			// 1.0=full saturation, 0.0=grayscale
	half fFinalLum = dot(cScene.rgb, LUMINANCE_VECTOR); 	
 	cScene.rgb = lerp((half3)fFinalLum, cScene.rgb, fSaturation); 

	// contrast enhance
	half fInvContrast = 1.15;		// 2.0 = contrast enhanced, 1.0=normal contrast, 0.01= max contrast reduced
	cScene.rgb = (cScene.rgb-0.5f)*fInvContrast+0.5f;	

	return cScene;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

half4 ApplyBlueShift(in vert2frag IN, in half4 cSceneIN, in half fLum )
{
  half4 cScene = cSceneIN;
  // Blue shift for stocopic (dark) scenes

  // Possible improvements: 
  //    - this should be physically more correct other that just visual hint ( Check: "A Spatial Post-Processing Algorithm for Images of Night Scenes")
  //    - noise quality should be improved
#if %_RT_SAMPLE1
	// Values hand-tweaked for non-sRGB
	half fLumBlendMul = 5.0;                   
	half3 cBlueTarget = half3( 0.8f, 0.8f, 1.4f);

#if %_RT_SAMPLE0
	// Values hand-tweaked for sRGB
	cBlueTarget = half3( 0.8f, 0.8f, 1.0f);
	cBlueTarget = cBlueTarget * cBlueTarget;
	fLumBlendMul = 32;
#endif

	cBlueTarget *= fLum;
	cScene.rgb = lerp(cBlueTarget * ( 1.0h + tex2D(noiseMap,IN.baseTC.wz).xyz ), cScene.rgb,  saturate(HDRParams3.x + fLumBlendMul * fLum));
#endif

  return cScene;

}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Exponentional mappping 
half4 ExpMapping( in vert2frag IN, in half4 cScene, in half4 cBloom, in half fAdaptedLum, in half fVignetting )
{
	half fLum = GetLuminance( cScene.rgb );
	fAdaptedLum = EyeAdaption( fAdaptedLum );

	// Exposure
	// Crysis 1 defaults: HDRParams1.y = 3, HDRParams1.z = 10

#if !%_RT_SAMPLE4
  half fAdaptedLumDest = HDRParams1.y / (1e-6 + 1.0h + HDRParams1.z * fAdaptedLum);
#else
  // pre-computing on cpu instead
	half fAdaptedLumDest = HDRParams1.y;
#endif

  cScene = ApplyBlueShift( IN, cScene, fLum );

#if USE_LUM_CONTRAST
	// Adjustable contrast in low luminance areas
	//cScene.xyz = lerp( pow( cScene.xyz, HDRParams2.z ), cScene.xyz, saturate( fLum * HDRParams2.w ) );

  // a bit more optimal version
  half fLumLerp = saturate( fLum );
  cScene.xyz= pow(cScene.xyz,HDRParams2.z + fLumLerp* ( 1 - HDRParams2.z) );
#endif

	// Tone mapping
	cScene.xyz = 1 - exp2( -fVignetting * (fAdaptedLumDest * cScene.xyz +cBloom  ));

	return cScene;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Drago's logarithmic mapping test
half4 DragoLogMapping( in vert2frag IN, in half4 cScene, in half4 cBloom, in half fAdaptedLum, in half fVignetting )
{
	fAdaptedLum = EyeAdaption( fAdaptedLum ) ;

	half p = 0.85h;
	half ld = 100.0h;

	half3 cSceneDiv = pow( (cScene.xyz / fAdaptedLum) , log( p ) / log( 0.5h ) );
	cScene.xyz = log( 1.0h + cScene.xyz ) / log( 2.0h + 8.0h * cSceneDiv );
	cScene.xyz *= (ld / 100.0h) / log( 1.0h + fAdaptedLum);

	// results: tends to oversaturate colors / hard to tweak

	return cScene;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Schlick's uniform rational quantization
half4 SchlickUniformMapping( in vert2frag IN, in half4 cScene, in half4 cBloom, in half fAdaptedLum, in half fVignetting )
{
	
	fAdaptedLum = EyeAdaption( fAdaptedLum );

	// todo: should not be lum, but lum_max and lum_min - assuming for test: lum max is just 10.0h more
	half fMaxLum = fAdaptedLum + 100.0h;

	half k = 0.8h;
	half ld = 256.0h;
	half3 p = (ld / 256.h) * fMaxLum / fAdaptedLum * (1 - k + k* cScene * rsqrt( fAdaptedLum* fMaxLum ) );

	cScene.xyz =fVignetting *  p * cScene.xyz / ( cScene.xyz * max(p - 1, 0) +fMaxLum );

	// results: behaves mostly nice, colors tend to not feel saturated though - cheap

	return cScene;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

half4 ReinhardMapping( in vert2frag IN, in half4 cScene, in half4 cBloom, in half fAdaptedLum, in half fVignetting )
{
	fAdaptedLum = EyeAdaption( fAdaptedLum );
	fAdaptedLum *= fAdaptedLum;
	
	half3 cXYZ = RGBtoXYZ(cScene);

  cXYZ.x *= fVignetting * (1.0h + (cXYZ.x / (fAdaptedLum ))) / (1.0h + cXYZ.x);

  // adjustable contrast in low luminance areas - test

	//half fLumScale = 20.0h;
	//cXYZ.x *= fVignetting * (1.0h + (cXYZ.x / (fAdaptedLum * fLumScale))) / (1.0h + cXYZ.x);	
	//half flum = GetLuminance( cScene.xyz );
	//cXYZ.x = lerp( pow( cXYZ.x, 1.25 ), cXYZ.x,  saturate( pow(cXYZ.x, 2)*  100 ));

	cScene.xyz =XYZtoRGB(cXYZ) + cBloom;

	// results: overall is nice, but tends to oversaturate colors - particularly visible in bright sources (sun)

	return cScene;
}

////////////////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////////////

pixout HDRFinalScenePS(vert2frag IN)
{
  pixout OUT = (pixout)0;

#if PS3  
  #pragma sce-cgc("-texformat default RGBA8");
  #pragma sce-cgc("-regcount 9"); 
  #pragma sce-cgc("-po NumTemps=9");
#endif

#if D3D10
  // temporary workaround for d3d10 hlsl compiler bug (hlsl sampler register mapping not matching assembly)
  OUT.Color = tex2D( baseMap, IN.baseTC.xy);
  OUT.Color += tex2D( lumMap, IN.baseTC.xy);;
  OUT.Color += tex2D( bloomMap0, IN.baseTC.xy);
  OUT.Color += tex2D( bloomMap1, IN.baseTC.xy);
  OUT.Color += tex2D( bloomMap2, IN.baseTC.xy);  
  OUT.Color += tex2D( colorChartMap, IN.baseTC.xy);
  OUT.Color += tex2D( noiseMap, IN.baseTC.xy);
#endif

  half4 vSample = tex2D(baseMap, IN.baseTC.xy) * HDRParams2.y;

  half4 cBloom0 = tex2D(bloomMap0, IN.baseTC.xy);
  half4 cBloom1 = tex2D(bloomMap1, IN.baseTC.xy);
  half4 cBloom2 = tex2D(bloomMap2, IN.baseTC.xy);

  // 2.0, 1.15, 0.45 - handtweaked values to get nice sharp falloff (keeping backward compatibility with crysis1)
  half4 cBloom = (cBloom0 * 2.0h + cBloom1 * 1.15h * 0.5h + cBloom2 * 0.45h* 0.5h);

  half fAdaptedLum = GetLuminanceMap(lumMap, 0.5h);

	//half fCenterDist = dot((IN.baseTC.xy*2-1), (IN.baseTC.xy*2-1));
	//half fVignetting = saturate(1 - (fCenterDist - HDRParams3.z) * HDRParams3.w);
  half fVignetting = tex2D(vignettingMap, IN.baseTC.xy);  

#if USE_REINHARD_MAPPING_TEST

	vSample = ReinhardMappingTest( IN, vSample, cBloom, fAdaptedLum, fVignetti);

#elif USE_EXP_MAPPING

	vSample = ExpMapping( IN, vSample, cBloom, fAdaptedLum, fVignetting);

#elif USE_DRAGO_LOG_MAPPING

	vSample = DragoLogMapping( IN, vSample, cBloom, fAdaptedLum, fVignetting);

#elif USE_SCHLICK_UNIFORM_MAPPING

	vSample = SchlickUniformMapping( IN, vSample, cBloom, fAdaptedLum, fVignetting);

#elif USE_REINHARD_MAPPING

	vSample = ReinhardMapping( IN, vSample, cBloom, fAdaptedLum, fVignetting);

#endif

  // Apply color chart

//  //  - note: color transformations always in gamma space
//  bool bSRGB = false;
//#if %_RT_SAMPLE0
//  bSRGB = true;
//#endif
//
//#if %_RT_SAMPLE3
//  if( bSRGB )
//    vSample.xyz = sqrt( vSample.xyz );
//
//	LookupColorChart(colorChartMap, vSample.xyz);
//
//  if( bSRGB )
//    vSample.xyz *= vSample.xyz;
//#endif

  OUT.Color = vSample;
 
  return OUT;
}

pixout HDRFinalDebugScenePS(vert2frag IN)
{
  pixout OUT;

  float4 sample = 0;
  for(int i=0; i<4; i++)
  {
    sample += tex2D(baseMap, IN.baseTC.xy + SampleOffsets[i].xy);
  }
  float4 vSample = tex2D(baseMap, IN.baseTC.xy);
  sample += vSample;
  
  //float fVal = dot(sample.xyz, half3(1,1,1));
  
  float4 s = 1;
  s.xyz = GetLuminance( vSample.xyz );
//  if (isnan(sample.x))
//  if (!(sample.x>0 && sample.x<20000.0f))
  if (sample.x>10000 || sample.y>10000 || sample.z>10000)
		s = half4(1,0,0,0);

  if (sample.x<0 || sample.y<0 || sample.z<0)
		s=float4(0,1,0,1);

  OUT.Color = s;
  
  return OUT;
}

//===================================================================================

void FogPassCommon (in vert2fragFog IN, out float sceneDepth, out half4 localFogColor, out float3 worldPos, out float3 cameraToWorldPos)
{
  float2 sDepthRG;
#if XENON || PS3
	sDepthRG = GetLinearDepth(zMap, IN.baseTC.xy);
  sceneDepth = sDepthRG.x;
#else
  sDepthRG = tex2D(zMap, IN.baseTC.xy).rg;   
  sceneDepth = GetLinearDepth(sDepthRG.x);   
#endif

  cameraToWorldPos = sceneDepth * IN.CamVec.xyz;
  worldPos = cameraToWorldPos + vfViewPos.xyz;

  localFogColor = GetVolumetricFogColor(worldPos, cameraToWorldPos, sceneDepth);

#if %_RT_FSAA
  localFogColor.a = sDepthRG.y;
#endif
}

float2 fogDepthTestBlend;

pixout FogPassPS(vert2fragFog IN)
{
  pixout OUT;

#if %_RT_DEBUG0 && %_RT_DEBUG1 && %_RT_DEBUG2 && %_RT_DEBUG3
    OUT.Color = NumInstructions;
    return OUT;
#endif

	float sceneDepth;
	half4 localFogColor;
	float3 worldPos, cameraToWorldPos;

	FogPassCommon(IN, sceneDepth, localFogColor, worldPos, cameraToWorldPos);
	localFogColor.a = 1.0 - localFogColor.a;


#if %_RT_SAMPLE0
	localFogColor.a *= saturate(sceneDepth * fogDepthTestBlend.x + fogDepthTestBlend.y);
#endif  


  // Re-scale range
  localFogColor.xyz *= HDRParams2.y;


#if PS3 && %_RT_HDR_MODE

  // PS3 HDR rendering is merging fog pass with scene hdr decode pass
  half4 cScene = DecodeHDRBuffer( tex2D(sceneMap1, IN.baseTC.xy) );
  OUT.Color = lerp( cScene, localFogColor, localFogColor.w );

#else

  HDROutput(OUT, localFogColor, 1);

#endif
  
  return OUT;
}

float4 LightningPos;				
float4 LightningColSize;
				
pixout FogPassWithLightningPS(vert2fragFog IN)
{
  pixout OUT;

#if %_RT_DEBUG0 && %_RT_DEBUG1 && %_RT_DEBUG2 && %_RT_DEBUG3
    OUT.Color = NumInstructions;
    return OUT;
#endif

	half sceneDepth;
	//half4 localFogColor;
	half3 worldPos, cameraToWorldPos;
	
	//FogPassCommon(IN, sceneDepth, localFogColor, worldPos, cameraToWorldPos);
	
  half2 sDepthRG = tex2D(zMap, IN.baseTC.xy).rg;
  sceneDepth = sDepthRG.x;   

  cameraToWorldPos = sceneDepth * IN.CamVec.xyz;
  worldPos = cameraToWorldPos + vfViewPos.xyz;
	

	/////////////////////////////////////////////////////////////
	// lightning computation... 
	// TODO: Optimize to fit into ps_2_0 limits!
	
	float atten = LightningColSize.w;	
	float3 c = atten * ( LightningPos.xyz - vfViewPos.xyz );
	float3 d = atten * cameraToWorldPos;
		
	float u = dot( c, c ) + 1;
	float v = -2 * dot( c, d );
	float w =  dot( d, d );
	float div = rsqrt( 4 * u * w - v * v );	
	//float lightning = sqrt( w ) * 2 * ( atan( ( v + 2 * w ) * div ) - atan( v * div ) ) * div; 
	float2 atan_res = atan( float2( v + 2 * w, v ) * div );
	float lightning = sqrt( w ) * 2 * ( atan_res.x - atan_res.y ) * div; 
    
  /////////////////////////////////////////////////////////////
	
  half4 Color = half4(LightningColSize.xyz * lightning, 1);
  
  HDROutput(OUT, Color, 1);
  
  return OUT;
}

pixout StretchHDRPS(vert2frag IN)
{
  pixout OUT;
  half4 sceneColor = tex2D(sceneMap0, IN.baseTC.xy);
  OUT.Color = sceneColor;
  return OUT;
}

pixout EncodeHDRPS(vert2frag IN)
{
  pixout OUT;
	  
  half4 sceneColor = tex2D(sceneMap0, IN.baseTC.xy);
  OUT.Color = EncodeRGBK(sceneColor, SCENE_HDR_MULTIPLIER);

  return OUT;
}

pixout Downscale4x4PS(vert2frag IN)
{
  pixout OUT;
  
  half4 sample = 0.0f;

  int nIter = 16;
  for(int i=0; i<nIter; i++)
  {
    float2 tc = IN.baseTC.xy + SampleOffsets[i].xy;
    sample.xyz += tex2D(sceneMap0, tc).xyz;
  }
      
  OUT.Color = sample / (float)nIter;
  
  return OUT;
}

pixout Downscale4x4_ToLDRPS(vert2frag IN)
{
  pixout OUT;
  
  half4 sample = 0.0f;

  int nIter = 16;
  for(int i=0; i<nIter; i++)
  {
    float2 tc = IN.baseTC.xy + SampleOffsets[i].xy;
    sample.xyz += tex2D(sceneMap0, tc).xyz;
  }
      
  OUT.Color = EncodeRGBK(sample / (float)nIter, SCENE_HDR_MULTIPLIER);
  
  return OUT;
}


////////////////////////////////////////////////////////////////////////////////////////////////////
/// DecodeIntoHDRTargetPS: decode encoded RT into HDRTarget ///////// //////////////////////////////

pixout DecodeIntoHDRTargetPS( vtxOut IN )
{
  pixout OUT;
	  
  // todo: profile merging this into fog pass (fog pass near clip optimization will be gone though)
  OUT.Color = DecodeHDRBuffer( tex2D(sceneMap0, IN.baseTC.xy) );

  return OUT;
}

//=======================================================

struct app2vertLI
{
  float4 Position  : POSITION;
  float2 baseTC0    : TEXCOORD0;
  float3 baseTC1    : TEXCOORD1;
};

struct vert2fragLI
{
  float4 HPosition  : POSITION;
  float4 Info0      : TEXCOORD0;
  float4 Info1      : TEXCOORD1;
};

vert2fragLI LightInfoVS(app2vertLI IN)
{
  vert2fragLI OUT = (vert2fragLI)0; 

  // Position in screen space.
  float4 vPos = IN.Position;
  OUT.HPosition = vPos;
  OUT.Info0.xy = IN.baseTC0.xy;
  OUT.Info1.zw = IN.baseTC1.xy;
  
  return OUT;
}


pixout LightInfoPS(vert2fragLI IN)
{
  pixout OUT;
	  
  OUT.Color.xy = IN.Info0.xy;
  OUT.Color.zw = IN.Info1.xy;

  return OUT;
}


// HDR post-processing techniques

technique HDRSampleLumInitial
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRSampleLumInitialPS();
  }
}

technique HDRSampleLumIterative
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRSampleLumIterativePS();
  }
}

technique HDRCalculateAdaptedLum
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRCalculateAdaptedLumPS();
  }
}

technique HDRBrightPassFilter
{
  pass p0
  {
    VertexShader = compile PROFILE_VS TransformVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRBrightPassFilterPS();
  }
}

technique HDRFinalPass
{
  pass p0
  {
    VertexShader = compile PROFILE_VS TransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRFinalScenePS();
  }
}

technique HDRFinalDebugPass
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS HDRFinalDebugScenePS();
  }
}

//======================================================================

technique FogPass
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedFogVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS FogPassPS();
  }
}

technique FogPassWithLightning
{
  pass p0
  {    
    VertexShader = compile PROFILE_VS PreTransformedFogVS();
    PixelShader = compile PROFILE_PS FogPassWithLightningPS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
  }
}

technique StretchHDR
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS StretchHDRPS();
  }
}


technique Encode_ToLDR
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS EncodeHDRPS();
  }
}

technique DecodeIntoHDRTarget
{
  pass p0
  {
    VertexShader = compile PROFILE_VS TransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS DecodeIntoHDRTargetPS();
  }
}

technique DownScale4x4
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS Downscale4x4PS();
  }
}

technique DownScale4x4_EncodeLDR
{
  pass p0
  {
    VertexShader = compile PROFILE_VS PreTransformedVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS Downscale4x4_ToLDRPS();
  }
}

technique LightInfo
{
  pass p0
  {
    VertexShader = compile PROFILE_VS LightInfoVS();
    
    ZEnable = false;
    ZWriteEnable = false;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS LightInfoPS();
  }
}

//======================================================================

struct vert2frag_zcullrecover
{
	float4 hPos : POSITION;
};

struct pixout_zcullrecover
{
	half4 col : COLOR0;
  float  Depth  : DEPTH;
};

vert2frag_zcullrecover ZCullRecoverVS(app2vert IN)
{
	vert2frag_zcullrecover OUT = (vert2frag_zcullrecover) 0;
	OUT.hPos = float4(IN.Position.xy, 0.0001, 1);
	return OUT;
}

pixout_zcullrecover ZCullRecoverPS(vert2frag_zcullrecover IN)
{ 
	pixout_zcullrecover OUT=(pixout_zcullrecover)0;
	OUT.Depth	=	1.f;
  return OUT;
}

technique ZCullRecover
{
  pass p0
  {
    VertexShader = compile PROFILE_VS ZCullRecoverVS();
    
    ZEnable = true;
    ZWriteEnable = true;
    CullMode = None;
    
    PixelShader = compile PROFILE_PS ZCullRecoverPS();
  }
}

/////////////////////// eof ///
